metadata
- 翻訳者: haruyama480
- (訳注)は翻訳者によるもの
- この文章は、markdownで書かれ、pdfに変換された後google docsに公開されます

Russ Coxによる正規表現についての4つ記事の1つ目
- https://swtch.com/~rsc/regexp/regexp1.html
- https://swtch.com/~rsc/regexp/regexp2.html
- https://swtch.com/~rsc/regexp/regexp3.html
- https://swtch.com/~rsc/regexp/regexp4.html
- その他リンク https://swtch.com/~rsc/regexp/

[Creative Commons Attribution License](https://creativecommons.org/licenses/by/4.0/) に基づき翻訳&公開します。

以下、翻訳

---

## はじめに
これは正規表現マッチングに対する2つのアプローチの物語です。一つはPerlを含む多くの言語の標準インタプリタで広く使われているものです。もう一つは、awk や grep の実装をはじめとする、ごく一部の場所でしか使われていません。この2つのアプローチの性能は大きく異なります。

図: $a^n$ に対して $a?^na^n$ にマッチする時間

<tr><td valign="bottom"><img src="https://swtch.com/~rsc/regexp/grep3p.png" alt="Perl graph" width="301" height="148"></td><td width="20"></td><td valign="bottom"><img src="https://swtch.com/~rsc/regexp/grep4p.png" alt="Thompson NFA graph" width="301" height="148">
</td></tr>

文字列の繰り返しを表すために上付き文字を使うことにします。つまり、$a?^3a^3$ は $a?a?a?aaa$ の省略形です。2つのグラフは、文字列 $a^n$ に対して正規表現 $a?^na^n$ をマッチさせるために各アプローチが必要とする時間をプロットしたものです。

Perlでは29文字の文字列をマッチさせるのに60秒以上かかることに注目してください。もう一方のアプローチは、後述する理由からThompson NFAと名付けられ、文字列をマッチさせるのに20マイクロ秒を必要とします。これはタイプミスではありません。Perlのグラフは秒単位で、Thompson NFAのグラフはマイクロ秒単位で時間をプロットしています。つまり、Thompson NFAの実装は、29文字の極小文字列で実行する場合、Perlの100万倍高速です。Perlが1015年以上かかるのに対して、トンプソンNFAは100文字の文字列を200マイクロ秒以下で処理します。(Perlは、同じアルゴリズムを使用する多数の一般的なプログラムの中で最も人目を引く例に過ぎません。上のグラフは、Python、PHP、Ruby、あるいは多くの他の言語でも成立するでしょう。この記事の後半にあるより詳細なグラフは、他の実装のデータを示しています)

このグラフを信じるのは難しいかもしれません。おそらくあなたはPerlを使ったことがあるだろうし、正規表現マッチングが特に遅いとは思わなかったでしょう。実際、ほとんどの場合、Perlの正規表現マッチングは十分に速いです。しかし、いわゆる「病的な(pathological)」正規表現を書くことは可能で、グラフが示すようにそれはPerlのマッチングが非常に遅いです。一方、Thompson NFAの実装では、病的な正規表現は存在しません。この2つのグラフを並べてみると、"なぜPerlはThompson NFAのアプローチを使わないのか？"という疑問が湧いてきます。それは可能であり、そうすべきなのだ、というのが本記事の趣旨です。

歴史的に見ると、正規表現は、優れた理論がいかに優れたプログラムにつながるかを示す、コンピュータサイエンスの輝かしい例のひとつです。正規表現はもともと単純な計算モデルとして理論家によって開発されましたが、Ken ThompsonによってCTSS用のテキストエディタQEDの実装の際にプログラマに紹介されました。 Dennis Ritchie も、GE-TSS用のQEDの実装でこれに倣いました。ThompsonとRitchieはその後Unixを開発し、正規表現を導入しました。1970年代後半までには、正規表現はed、sed、grep、egrep、awk、lexといったツールでUnixの重要な特徴となっていました。

今日、正規表現は、優れた理論を無視することがいかに悪いプログラムにつながるかを示す輝かしい例にもなっています。今日の一般的なツールで使われている正規表現の実装は、30年前のUnixツールの多くで使われていたものよりかなり遅いです。

この記事では、優れた理論についてレビューします。具体的には、正規表現、有限オートマトン、そして1960年代半ばにケン・トンプソンが発明した正規表現検索アルゴリズムについてです。また、理論を実践し、Thompsonのアルゴリズムの簡単な実装を説明します。この実装はC言語で400行に満たないもので、上記のPerlと対決したものである。この実装は、Perl、Python、PCREなどで使われている、より複雑な現実世界の実装より優れています。この記事は、理論が実際の実装でどのように実践されるかという議論で締めくります。

## 正規表現
正規表現は文字列の集合を記述するための表記法です。ある文字列が正規表現で記述された集合に含まれる場合、正規表現がその文字列にマッチすると表現します。

最も単純な正規表現は1つのリテラル文字です。特別なメタ文字 `*+?()|` を除いて、文字はそれ自身にマッチします。メタ文字にマッチするには、バックスラッシュでエスケープします。'\\+' は文字通りプラス文字にマッチします。

2つの正規表現を代替(alternate)または連結(concatenate)して新しい正規表現を構築することができます。`e1` が s にマッチし、`e2` が t にマッチする場合、`e1|e2` は s または t にマッチし、`e1e2` は st にマッチします。

メタ文字 `\*,+,?` は反復演算子です。`e1*` は`e1`にマッチする0個以上の(異なるかもしれない)文字列のシーケンスにマッチします。`e1+` は1個以上にマッチします。`e1?` は0か1個にマッチします。

演算子の優先順位は、結合の弱いものから強い順に、最初に代替演算子、次に連結演算子、最後に反復演算子となります。算術式のように、明示的な括弧を使って異なる意味を強制することができます。例えば、`ab|cd`は`(ab)|(cd)`と等価であり、`ab*`は`a(b*)`と等価です。

ここまでに説明した構文は、伝統的なUnix egrep正規表現構文のサブセットです。このサブセットは、すべての正規言語を記述するのに十分です。大まかに言えば、正規言語とは、固定された量のメモリを使用して、テキストを一度通過するだけでマッチさせることができる文字列の集合です。新しい正規表現機能（特にPerlやそれをコピーしたもの）は、[多くの新しいオペレーターやエスケープシーケンスを追加しました](https://perldoc.perl.org/)。これらの追加により、正規表現はより簡潔に、時にはより難解になりますが、通常はより強力になるわけではありません。これらの新しく斬新な正規表現は、ほとんどの場合、伝統的な構文を使った長い等価表現を持っています。

一般的な正規表現の拡張機能のひとつに、後方参照(backreference)と呼ばれる力を提供するものがあります。後方参照は、`\1`や`\2`のように、以前の括弧付き表現によってマッチした文字列、そしてその文字列のみにマッチします。例えば、`(cat|dog)\1`はcatcatとdogdogにはマッチしますが、catdogやdogcatにはマッチしません。理論用語としては、後方参照を含む正規表現は、正規表現とはみなされません。後方参照が追加する力は大きなコストがかかります。最悪の場合、最善と知られた実装だとしても指数関数的な検索アルゴリズムが必要です。まさにPerlがそうです。Perl（および他の言語）は、もはや後方参照のサポートを取り除くことはできません。しかし、後方参照を含まない正規表現が与えられた場合、はるかに高速なアルゴリズムを採用することができます。この記事は、それらの高速なアルゴリズムについてです。

## 有限オートマトン (Finite Automata)

文字列の集合を記述するもうひとつの方法は、有限オートマトンです。有限オートマトンはステートマシンとも呼ばれ、ここでは「オートマトン」と「マシン」を同じ意味で使います。

簡単な例として、a(bb)+aという正規表現にマッチする文字列の集合を認識するマシンを示します。

<img src="https://swtch.com/~rsc/regexp/fig0.png" alt="DFA for a(bb)+a" width="278" height="54">

有限オートマトンは常にいずれかの状態にあります。（円の中の数字は、この議論を容易にするためのラベルであり、マシンの動作の一部ではありません）。文字列を読むと、状態から状態へと遷移します。このマシンには、開始状態s0とマッチング状態s4という2つの特別な状態があります。開始状態は単独の矢じり付き描かれ、マッチング状態は二重丸で描かれます。

マシンは入力文字列を一度に1文字ずつ読み、入力に対応する矢印に従って状態から状態へ遷移します。入力文字列がabbbbaだとします。マシンが文字列の最初の文字であるaを読むとき、マシンは開始状態s0にあります。aの矢印に従って状態s1に遷移します。マシンが文字列の残りの部分を読むと、このプロセスが繰り返され、bならs2へ、bならs3、bならs2、bならs3、そして最後にaを見てs4に到達します。

<img src="https://swtch.com/~rsc/regexp/fig1.png" alt="DFA execution on abbbba" width="357" height="426">

マシンはs4というマッチング状態で終了するので、文字列はマッチします。マシンが非マッチング状態で終了すると、文字列にマッチしません。マシンの実行中のどの時点でも、現在の入力文字に対応する矢印がない場合、マシンは早期に実行を停止します。

どのような状態であれ、任意の入力文字が導く新しい状態はせいぜい1つであるため、これまで考えてきたマシンは決定論的有限オートマトン（DFA）と呼ばれます。また、複数の取りうる状態の中から次の状態を選択しなければならないマシンも作ることができます。例えば、このマシンは前のものと等価ですが、決定論的ではありません。

<img src="https://swtch.com/~rsc/regexp/fig2.png" alt="NFA for a(bb)+a" width="278" height="54">

このマシンは非決定的です。なぜなら、状態s2で`ab`を読む場合、次の状態に複数の選択肢があるからです。例えば、次の`bb`を見ることを期待してs1に戻ることもできるし、最後の`a`を見ることを期待してs3に進むこともできます。マシンは文字列の残りを見るために先読みすることができないので、どちらが正しい判断かを知ることができません。この状況では、マシンに常に正しく推測させることが興味深い結果になります。このようなマシンは非決定性有限オートマトン（NFAまたはNDFA）と呼ばれます。NFAは、入力文字列を読み取り、一致する状態への矢印をたどる方法が存在すれば、入力文字列をマッチしたと判定します。

ときどきNFAに、対応する入力文字を持たない矢印を許すと便利なことがあります。このような矢印をラベルを付けずに表現します。NFAは常にラベルのない矢印に対して入力を読まずに従うことを選択できます。このNFAは前の2つと等価ですが、ラベルのない矢印はa(bb)+aとの対応を最も明確にします。

<img src="https://swtch.com/~rsc/regexp/fig3.png" alt="Another NFA for a(bb)+a" width="278" height="39">

## 正規表現からNFAへの変換

正規表現とNFAはその表現力においてまったく等価であることがわかります。
つまり、すべての正規表現は等価なNFAを持ちます。 (これらは同じ文字列にマッチします。)、そしてその逆も同様です。(DFAもまたその表現力においてNFAや正規表現と等価であることがわかります。これは後ほど見ていきます。） 正規表現をNFAに変換する方法は複数あります。ここで述べる方法は、Thompsonが1968年のCACMの論文で最初に説明したものです。

正規表現のNFAは、演算子ごとに異なる構築を使って、各部分表現に対応する部分NFAから作られます。部分NFAはマッチング状態を持ちません。代わりに、何も指していない宙ぶらりんな矢印を1つ以上持ちます。構築プロセスは、これらの矢印をマッチング状態に接続することで完了します。

単一文字にマッチするNFAは次のようになります。

<img src="https://swtch.com/~rsc/regexp/fig4.png" alt="Single-character NFA" width="113" height="21">

連結`e1e2`のNFAは、`e1`マシンの最終矢印と`e2`マシンの開始矢印を接続します。(連結: concatnation)

<img src="https://swtch.com/~rsc/regexp/fig5.png" alt="Concatenation NFA" width="242" height="20">

代替`e1|e2`のNFAは、`e1`マシンか`e2`マシンのどちらかを選択する新しい開始状態を追加します。(代替: altanation)

<img src="https://swtch.com/~rsc/regexp/fig6.png" alt="Alternation NFA" width="202" height="62">

`e?`のNFAは、`e`マシンと空のパスの代替です。

<img src="https://swtch.com/~rsc/regexp/fig7.png" alt="Zero or one NFA" width="184" height="56">

`e*`のNFAは、同じような交替ですが、`e`マシンのマッチをスタートに戻るようにループさせます。

<img src="https://swtch.com/~rsc/regexp/fig8.png" alt="Zero or more NFA" width="184" height="56">

`e+`のNFAも、ループを作りますが、少なくとも1回は`e`を通過しなければなりません。

<img src="https://swtch.com/~rsc/regexp/fig9.png" alt="One or more NFA" width="190" height="41">


上の図から新しい状態の数を数えてみると、この手法は、括弧を除いた正規表現中の1文字または1メタ文字につき、ちょうど1つの状態が生成されることがわかります。したがって、最終的なNFAの状態数は、最大でも元の正規表現の長さに等しくなります。

前述したNFAの例と同様に、ラベルのない矢印を削除することは常に可能であり、また最初からラベルのない矢印なしでNFAを生成することも常に可能です。ラベルのない矢印があることで、NFAは読みやすく理解しやすくなり、またC言語での表現も単純になるので、このままにしておきます。

(訳注: ラベルのない→ラベルレスと表現するとわかりやすそう)

## 正規表現検索アルゴリズム

これで正規表現が文字列にマッチするかどうかを判定する方法がわかりました。それはつまり、正規表現をNFAに変換し、文字列を入力としてNFAを実行することです。NFAは、次の状態の選択に直面したときに完全に推測する能力が想定されていることを思い出してください。普通のコンピュータを使ってNFAを実行するには、この推測をシミュレートする方法を見つけなければなりません。

完全な推測をシミュレートする方法の一つは、1つの選択肢を想定し、それがうまくいかなければ、もう1つの選択肢を試すことです。例えば、文字列abbbに対してabab|abbbのNFAを実行することを考えてみましょう。

<img src="https://swtch.com/~rsc/regexp/fig10.png" alt="NFA for abab|abbb" width="364" height="79">

<img src="https://swtch.com/~rsc/regexp/fig11.png" alt="Backtracking execution on abbb" width="729" height="619">

ステップ0で、NFAはababと一致させるかabbbと一致させるかを選択する必要があります。図では、NFAはababを試みますが、ステップ3で失敗します。次にNFAはもう一方の選択肢を試し、ステップ4に進み、最終的にマッチします。このバックトラックなアプローチは単純な再帰的実装ですが、成功するまでに何度も入力文字列を読み込むことがあり得ます。文字列が一致しない場合、マシンは可能な限りの実行経路を諦めるまで試さなければなりません。この例では、NFAは2つの異なる経路しか試していませんが、最悪の場合、実行可能な経路は指数関数的に多くなり、実行時間が非常に遅くなるかもしれません。

完全な推測をシミュレートするための、より効率的だが複雑な方法は、両方の選択肢を同時に想定することです。この方法では、マシンが一度に複数の状態を持つようにシミュレートします。各文字を処理するために、その文字に一致するすべての矢印に沿ってすべての状態を進めます。

<img src="https://swtch.com/~rsc/regexp/fig12.png" alt="Parallel execution on abbb" width="329" height="511">

マシンは開始状態と開始状態からラベルのない矢印で到達可能なすべての状態から始まります。ステップ1と2では、NFAは同時に2つの状態をとります。ステップ3で、初めて状態セットは1つの状態に絞られます。この多状態アプローチは、入力を一度しか読み込まず、同時に両方の経路を試します。最悪の場合、NFAは各ステップですべての状態になる可能性がありますが、その結果、最悪でも文字列の長さに依存しない一定の計算量で済むため、任意の大きさの入力文字列を線形時間で処理することができます。これは、バックトラックアプローチが必要とする指数関数的な時間に比べて劇的な改善です。この効率性は、到達可能な状態の集合を追跡することに依存しますが、どの経路を使って到達したかには依存しません。n個のノードを持つNFAは、どのステップであっても到達可能な状態はn個しか存在しませんが、NFAを通るパスは $2^n$ 個あるかもしれません

## 実装
トンプソンは1968年の論文で多重状態シミュレーション(multiple-state simulation) アプローチを紹介しました。彼の定式化では、NFAの状態は小さなマシンコード列で表され、とりうる状態のリストは単なる関数呼び出しの命令列でした。要するに、トンプソンは正規表現を賢いマシンコードにコンパイルしました。それから40年後、コンピュータははるかに高速になり、コードのアプローチはそれほど必要ではなくなりました。以下のセクションでは、移植可能なANSI Cで書かれた実装を紹介します。完全なソースコード(400行以下) とベンチマークスクリプトは[オンラインで入手可能](https://swtch.com/~rsc/regexp/regexp-bytecode.c.txt)です。(Cやポインタに不慣れな読者や苦手な読者は、説明だけ読んで実際のコードは読み飛ばしてください)。

## 実装: NFAにコンパイル
最初のステップは、正規表現を等価なNFAにコンパイルすることです。私たちのCプログラムではNFAを、リンクされたState構造体のコレクションと表現します。
```c
struct State
{
	int c;
	State *out;
	State *out1;
	int lastlist;
};
```

各Stateは、cの値に応じて、次の3つのNFAフラグメントのいずれかを表します。

<img src="https://swtch.com/~rsc/regexp/fig13.png" alt="Possible per-State NFA fragments" width="340" height="109">

(`Lastlist` は実行時に使用され、次のセクションで説明されます)

Thompsonの論文に従い、コンパイラはpostfix記法(明示的な連結演算子としてドット(.)を追加する記法)で表現された正規表現からNFAを構築します。とある関数`re2post`は、`a(bb)+a`のようなinfixな正規表現を `abb.+.a.`のような等価なpostfix式に書き換えます。(「実際の」実装は、連結演算子としてではなく、ドットは「任意の文字」を表すメタ文字として使われるでしょう。また、実際の実装は明示的なpostfix式を構築するのではなく、パース時にNFAを構築することになるでしょう。しかし、postfix式の方が便利であり、Thompsonの論文により忠実です)。

(訳注: 逆ポーランド記法のように逆茂木な図を書くとわかりやすい。例: `abb.+.a.` → `(a ((b b .) +) .) a .`)

コンパイラはpostfix式をスキャンしながら、計算されたNFAフラグメントのスタックを保持します。リテラルなら新たにNFAフラグメントをスタックにプッシュし、演算子ならフラグメントをスタックからポップしてから新しいフラグメントをプッシュします。例えば、`abb.+.a.`のabbをコンパイルした後、スタックにはa、b、bという3つのNFAフラグメントが格納されます。続く`.`のコンパイルでは、bという2つのNFAフラグメントをスタックからポップし、連結`bb.`を表す1つのNFAフラグメントをプッシュします。各NFAフラグメントは、その開始状態と出て行く複数の矢印によって定義されます。

```c
struct Frag
{
	State *start;
	Ptrlist *out;
};
```

startはフラグメントの開始状態を指し、outはまだ何にも接続されていないState\*を指すポインタのリストです。これらはNFAフラグメントの宙ぶらりんの矢印です。

いくつかのヘルパー関数はポインタリストを操作します。
```c
Ptrlist *list1(State **outp);
Ptrlist *append(Ptrlist *l1, Ptrlist *l2);

void patch(Ptrlist *l, State *s);
```

list1は単一ポインタoutpを含む新しいポインタリストを作成します。appendは2つのポインターリストを連結し、結果を返します。patchはポインタリストlの宙ぶらりんの矢印を状態sに接続します。言い換えると、lの各ポインタoutpに対して\*outp = sをセットします。

これらのプリミティブとフラグメントのスタックがあれば、コンパイラはpostfix式に対する単純なループとなります。最後に、1つのフラグメントが残り、マッチング状態にpatchすることで、NFAが完成します。
```c
State*
post2nfa(char *postfix)
{
	char *p;
	Frag stack[1000], *stackp, e1, e2, e;
	State *s;

	#define push(s) *stackp++ = s
	#define pop()   *--stackp

	stackp = stack;
	for(p=postfix; *p; p++){
		switch(*p){
		/* _compilation cases, described below_ */
		}
	}

	e = pop();
	patch(e.out, matchstate);
	return e.start;
}
```

特定のコンパイルのケースを使って、前述の翻訳ステップを模倣してみましょう。

リテラル文字
```c
default:
	s = state(*p, NULL, NULL);
	push(frag(s, list1(&s->out));
	break;
```
<img src="https://swtch.com/~rsc/regexp/fig14.png" alt="" width="61" height="24">

連結
```c
case '.':
	e2 = pop();
	e1 = pop();
	patch(e1.out, e2.start);
	push(frag(e1.start, e2.out));
	break;
```
<img src="https://swtch.com/~rsc/regexp/fig15.png" alt="" width="182" height="20">

代替
```c
case '|':
	e2 = pop();
	e1 = pop();
	s = state(Split, e1.start, e2.start);
	push(frag(s, append(e1.out, e2.out)));
	break;
```
<img src="https://swtch.com/~rsc/regexp/fig16.png" alt="" width="140" height="62">

0か1
```c
case '?':
	e = pop();
	s = state(Split, e.start, NULL);
	push(frag(s, append(e.out, list1(&s->out1))));
	break;
```
<img src="https://swtch.com/~rsc/regexp/fig17.png" alt="" width="140" height="68">

0以上
```c
case '*':
	e = pop();
	s = state(Split, e.start, NULL);
	patch(e.out, s);
	push(frag(s, list1(&s->out1)));
	break;
```
<img src="https://swtch.com/~rsc/regexp/fig18.png" alt="" width="131" height="68">

1以上
```c
case '+':
	e = pop();
	s = state(Split, e.start, NULL);
	patch(e.out, s);
	push(frag(e.start, list1(&s->out1)));
	break;
```
<img src="https://swtch.com/~rsc/regexp/fig19.png" alt="" width="140" height="53">

## 実装: NFAをシミュレート
NFAを構築できたので、次にシミュレーションを行います。シミュレーションには、単に配列リストとして格納されたStateの集合を追跡する必要があります。
```c
struct List
{
	State **s;
	int n;
};
```

シミュレーションは2つのリストを使います。clistはNFAが現在置かれている状態の集合で、nlistは現在のキャラクタを処理した後にNFAが次に遷移する状態の集合です。実行ループでは、clistを初期化して開始状態だけを格納し、マシンを1ステップずつ実行します。
```c
int
match(State *start, char *s)
{
	List *clist, *nlist, *t;

	/* l1 と l2 は事前にアロケーションされたグローバル変数 */
	clist = startlist(start, &l1);
	nlist = &l2;
	for(; *s; s++){
		step(clist, *s, nlist);
		t = clist; clist = nlist; nlist = t;	/* clist と nlist を swap */
	}
	return ismatch(clist);
}
```

ループのイテレーションごとにアロケートするのを避けるため、matchは事前にアロケートした2つのリストl1とl2をclistとnlistとして使用し、各ステップ後にその2つを入れ替えます。

もし最終的な状態のリストにマッチング状態が含まれていれば、その文字列はマッチします。
```c
int
ismatch(List *l)
{
	int i;

	for(i=0; i<l->n; i++)
		if(l->s[i] == matchstate)
			return 1;
	return 0;
}
```

addstateは状態をリストに追加しますが、すでにリストにある場合は追加しません。追加のたびにリスト全体をスキャンするのは非効率的なので、代わりに変数listidがリスト生成番号として機能します。addstateがsをリストに追加するとき、s->lastlistにlistidを記録します。もし2つが既に等しいなら、sは既に構築中のリストにあります。また、addstateはラベルのない矢印にも従います。もしsが、新しい状態を向いたラベルのない矢印を2つ持ったSplit状態である場合、addstateは、sの代わりにそれらの状態をリストに追加します。

(訳注: Splitがネストした場合ネスト先も見る必要がある。これは再帰実装によって実現される)

```c
void
addstate(List *l, State *s)
{
	if(s == NULL || s->lastlist == listid)
		return;
	s->lastlist = listid;
	if(s->c == Split){
		/* follow unlabeled arrows */
		addstate(l, s->out);
		addstate(l, s->out1);
		return;
	}
	l->s[l->n++] = s;
}
```

startlistは、開始状態だけを追加して初期の状態リストを作成します。
```c
List*
startlist(State *s, List *l)
{
	listid++;
	l->n = 0;
	addstate(l, s);
	return l;
}
```

最後に、stepは、現在のリストclistを使って次のリストnlistを計算しながら、1文字を過去のものとしてNFAを進めます。
```c
void
step(List *clist, int c, List *nlist)
{
	int i;
	State *s;

	listid++;
	nlist->n = 0;
	for(i=0; i<clist->n; i++){
		s = clist->s[i];
		if(s->c == c)
			addstate(nlist, s->out);
	}
}
```

## パフォーマンス
今説明したCの実装は、性能を念頭に置いて書かれたものではありません。そうだとしても、指数が十分大きければ、線形時間アルゴリズムの遅い実装は、指数時間アルゴリズムの速い実装を簡単に上回ることができます。いわゆる病的な正規表現について、さまざまな一般的な正規表現エンジンをテストしてみると、このことがよくわかります。

$a?^na^n$ という正規表現を考えてみましょう。これは文字列a^nにマッチします ($a?$ がどの文字にもマッチしないように選択され、文字列全体が $a^n$ にマッチします)。バックトラックする正規表現の実装では、最初に1を試し、次に0を試すことで、zero-or-oneである`?`を実装します。このような選択肢はn個あり、合計 $2^n$ 個の可能性があります。マッチするのは、最後の可能性である0を選ぶときだけです。従って、バックトラック法は $O(2^n)$ の時間を必要とし、n=25を超えてもあまりスケールしません。

対照的に、Thompsonのアルゴリズムは、約nの長さの状態リストを保持し、同じくnの長さの文字列を合計 $O(n^2)$ の時間で処理します。(入力が大きくなっても正規表現を一定に保つわけではないので、実行時間は超線形(superlinear)です。長さmの正規表現を長さnのテキストで実行する場合、Thompson NFAはO(mn)の時間を必要とします)。

次のグラフは、$a?^na^n$ が $a^n$ にマッチするかどうかを判定するのに要した時間をプロットしたものです。

<img src="https://swtch.com/~rsc/regexp/grep1p.png" alt="Performance graph" width="779" height="388">

グラフのY軸が対数スケールになっているのは、1つのグラフで幅広い時間を見ることができるようにするためです。

グラフから明らかなように、Perl、PCRE、Python、Rubyはすべて再帰的なバックトラックを使っています。PCREはn=23で正しい答えが得られなくなりますが、これは再帰的バックトラックを最大ステップ数で中止するからです。Perl 5.6では、Perlの正規表現エンジンは再帰的バックトラック検索を[メモ化すると言われており](http://perlmonks.org/index.pl?node_id=502408)、多少のメモリコストはかかるものの、後方参照が使用されていない限り、検索に指数関数的な時間がかかることはないはずです。パフォーマンスグラフが示すように、メモ化は完全ではありません。Perlの実行時間は、式の中に後方参照がなくても指数関数的に増加します。ここではベンチマークをとりませんでしたが、Javaもバックトラックする実装を使っています。実際、java.util.regexインターフェイスはバックトラックする実装を必要とします。 なぜなら、マッチするパスに任意のJavaコードを埋め込めるからです。PHPはPCREライブラリを使用しています。

太い青い線は、上で示したThompsonのアルゴリズムのC実装です。Awk、Tcl、GNU grep、GNU awkは、事前に計算するか、次の節で説明するon-the-flyな構築でDFAを作成します。

このテストは一般的でないコーナーケースにフォーカスしており、バックトラック実装に対して不公平であると主張する人もいるかもしれません。この議論は的外れです。すべての入力に対して、予測可能で一貫した高速な実行時間を持つ実装と、通常は高速に実行されるが、いくつかの入力に対しては何年も（あるいはそれ以上）CPU時間を要する実装のどちらかを選択するのであれば、その決断は単純なはずだ。また、今回のような大げさな例は実際にはめったに起こらないが、それほど大げさでない例もある。例えば、`(.*) (.*) (.*) (.*) (.*) (.*)` を使ってスペースで区切られた5つのフィールドを分割したり、一般的なケースを最初に列挙しないような代替を使ったりすることです。その結果、プログラマーはしばしば、どの構文が高価かを学習し、それを避けるか、いわゆる[最適化](https://metacpan.org/release/DANKOGAI/Regexp-Optimizer-0.15/view/lib/Regexp/Optimizer.pm)に頼ることになります。トンプソンのNFAシミュレーションを使えば、そのような適応は必要ありません。そこには高価な正規表現がないからです。

## NFAをキャッシュしてDFAを構築

DFAは一度に1つの状態にしかとらないため、NFAよりも実行効率が良いことを思い出してください。それらは次の状態を複数選択することがありません。どのようなNFAも、各DFAの状態がNFAの状態リストに対応する等価なDFAに変換することができます。

たとえば、ここに、前述したabab|abbbのNFAに状態番号を追加したものがあります。

<img src="https://swtch.com/~rsc/regexp/fig20.png" alt="NFA for abab|abbb" width="424" height="91">

等価なDFAは次のようになります。

<img src="https://swtch.com/~rsc/regexp/fig21.png" alt="DFA for abab|abbb" width="496" height="170">

DFAの各状態はNFAの状態リストに対応します。

ある意味、ThompsonのNFAシミュレーションは、等価なDFAを実行していると言えます。各リストはあるDFAの状態に対応し、step関数は、リストと次の文字が与えられたときに、次に入るDFAの状態を計算します。Thompsonのアルゴリズムは、DFAの各状態を必要に応じて再構築することで、DFAをシミュレートします。各ステップの後にこの作業を捨てるのではなく、予備メモリにリストをキャッシュすることで、将来的に計算を繰り返すコストを回避し、必要なときに同等のDFAを実質計算することができます。本節では、このようなアプローチの実装を紹介します。前節のNFAの実装から始めると、DFAの実装を構築するために必要な行数は100行未満です。

キャッシュを実装するために、まずDFAの状態を表す新しいデータ型を導入します。
```c
struct DState
{
	List l;
	DState *next[256];
	DState *left;
	DState *right;
};
```
DStateはリストlのキャッシュされたコピーです。配列nextには、入力可能な文字ごとに次の状態へのポインタが格納されています。具体的には、現在の状態がdで、次の入力文字がcの場合、`d->next[c]`が次の状態です。`d->next[c]`がNULLの場合、次の状態はまだ計算されていません。nextstateは、与えられた状態と文字に対して次の状態を計算し、記録して返します。

(訳注: Dstateは、DFAの1状態(NFAの状態の組み合わせ`l`)から次に遷移する状態のリストを保持する関数。left,rightはキャッシュを検索するための2分木を実装するためのフィールド(後述))

正規表現のマッチは、`d->next[c]`を繰り返したどり、必要に応じてnextstateを呼び出して新しい状態を計算することで行われます。
```c
int
match(DState *start, char *s)
{
	int c;
	DState *d, *next;

	d = start;
	for(; *s; s++){
		c = *s & 0xFF;
		if((next = d->next[c]) == NULL)
			next = nextstate(d, c);
		d = next;
	}
	return ismatch(&d->l);
}
```

計算されたすべてのDStateを保持するには、そのリストからDStateを検索できる構造体が必要です。そのために、ソートされたリストをキーとして、DStateをバイナリツリーに並べます。dstate関数は、与えられたリストからDStateを返し、必要であれば1つの割り当てを行います。
```c
DState*
dstate(List *l)
{
	int i;
	DState **dp, *d;
	static DState *alldstates;

	qsort(l->s, l->n, sizeof l->s[0], ptrcmp);

	/* look in tree for existing DState */
	dp = &alldstates;
	while((d = *dp) != NULL){
		i = listcmp(l, &d->l);
		if(i < 0)
			dp = &d->left;
		else if(i > 0)
			dp = &d->right;
		else
			return d;
	}

	/* allocate, initialize new DState */
	d = malloc(sizeof *d + l->n*sizeof l->s[0]);
	memset(d, 0, sizeof *d);
	d->l.s = (State**)(d+1);
	memmove(d->l.s, l->s, l->n*sizeof l->s[0]);
	d->l.n = l->n;

	/* insert in tree */
	*dp = d;
	return d;
}
```

nextstateはNFAのステップを実行し、対応するDStateを返します。
```c
DState*
nextstate(DState *d, int c)
{
	step(&d->l, c, &l1);
	return d->next[c] = dstate(&l1);
}
```

最後に、DFAの開始状態は、NFAの開始リストに対応するDStateです。
```c
DState*
startdstate(State *start)
{
	return dstate(startlist(start, &l1));
}
```

(NFAシミュレーションと同様、l1は事前に割り当てられたリストです)

DStatesはDFAの状態に対応しますが、DFAは必要になったものだけ構築されるます。もし探索中にDFAの状態に遭遇しなかった場合、それはまだキャッシュに存在しません。別の方法として、DFA全体を一度に計算することもできます。そうすることで、条件分岐がなくなり、マッチは少し速くなります。しかし、その代償として起動時間とメモリ使用量が増えます。

また、on-the-flyのDFA構築で使用されるメモリ量の上限も気になるかもしれません。Dstateはstep関数のキャッシュに過ぎないので、キャッシュが大きくなりすぎた場合、dstateの実装はこれまでのDFA全体を捨てることを選択できます。このキャッシュ置換ポリシーは、dstateとnextstateに数行のコードと、メモリ管理用に約50行のコードが追加するだけで実現できます。実装は[オンラインで入手できます](https://swtch.com/~rsc/regexp/dfa1.c.txt)。(Awk([リンク切れ](http://cm.bell-labs.com/cm/cs/awkbook/): [HNの声](https://news.ycombinator.com/item?id=2932637))は同じようなサイズ制限のあるキャッシュ戦略を使っており、キャッシュされるステートは32個までと決まっています。これは上のグラフにおいてn=28でパフォーマンスが不連続になっていることの説明になっています)。

正規表現から得られたNFAは、良い局所性(locality)を示す傾向があります。ほとんどのテキストでは実行時に、同じ状態を訪れ、同じ遷移矢印を何度もたどります。このため、キャッシュする価値があります。初めての矢印をたどるときは、NFAシミュレーションのように次の状態を計算する必要がありますが、将来その矢印をたどるときは、1回のメモリアクセスで済みます。実際のDFAベースの実装では、さらなる最適化によってさらに高速化できます。関連記事（未執筆）では、DFAベースの正規表現実装についてさらに詳しく説明します。

## Real worldな正規表現

実際のプログラムでの正規表現の使い方は、上で説明した正規表現の実装で扱えるものより多少複雑です。このセクションでは、一般的な複雑さについて簡単に説明します。これらのいずれかを完全に扱うことは、この入門記事の範囲を超えます。

文字クラス(character classes)。文字クラスは、`[0-9]`, `\w` `.`(ドット)であれ、代替の簡潔な表現に過ぎません。文字クラスはコンパイル時に代替表現に拡張できますが、新しい種類のNFAノードを追加して明示的に表現する方が効率的です。POSIXでは`[[:upper:]]`のような、現在のロケールによって意味が変わる特殊な文字クラスが定義されていますが、これらの対応が困難なのは、その意味を決定することであって、その意味をNFAにエンコードすることではありません。

エスケープシーケンス(escape sequence)。実際の正規表現構文は、メタキャラクタ (`\(`, `\)`, `\\`, etc.)にマッチさせる方法と、`\n`のようなタイピングが難しい文字を指定する方法の両方として、エスケープシーケンスを処理する必要があります。

カウントされた反復(counted repetition)。多くの正規表現実装は、パターンに正確にn個の文字列がマッチする`{n}`、n 以上 m 未満にマッチする`{n,m}`、n 個以上にマッチする`{n,}`というcountedな反復演算子を提供します。再帰的バックトラック実装では、ループを使用してカウントされた反復を実装できます。NFAまたはDFAベースの実装では、次のように繰り返しを展開する必要があります: `e{3}`を`eee`に、`e{3,5}`を`eeee?e?`に、`e{3,}`を`eee+`に展開します。

サブマッチの抽出(submatch extraction)。正規表現が文字列の分割や解析に使われる場合、入力文字列のどの部分がそれぞれの部分式にマッチしたかを知ることができると便利です。`([0-9]+-[0-9]+-[0-9]+)([0-9]+:[0-9]+)`のような正規表現が文字列(例えば日付と時刻)にマッチした後に、多くの正規表現エンジンは括弧で囲まれた各式にマッチしたテキストを利用できます。例えば、Perlで次のように書くことができます。
```perl
if(/([0-9]+-[0-9]+-[0-9]+) ([0-9]+:[0-9]+)/){
	print "date: $1, time: $2\n";
}
```
サブマッチ境界(submatch boundaries)の抽出は計算機科学の理論家によってほとんど無視されてきましたが、おそらく再帰的バックトラックを使うための最も説得力のある議論でしょう。しかし、Thompsonスタイルのアルゴリズムは、効率的な性能を放棄することなく、サブマッチ境界を追跡するように適応させることができます。第8版のUnix regexp(3)ライブラリは、1985年の時点でそのようなアルゴリズムを実装していました。

unanchored match。この記事では、正規表現が入力文字列全体とマッチすることを仮定しています。
実際には、正規表現にマッチする入力の部分文字列を見つけたいことがよくあります。Unixのツールは伝統的に、入力の可能な限り左端から始まる最も長くマッチする部分文字列を返します。eのunanchoredな検索は、サブマッチ抽出の特殊なケースです。それは`.*(e).*`を検索するようなもので、最初の`.*`はできるだけ短い文字列にマッチするように制約されています。

非貪欲な演算子(non-greedy operators)。伝統的なUnixの正規表現では、繰り返し演算子 `?, *, +` は、正規表現全体がマッチするようにしながら、できるだけ多くの文字列にマッチするように定義されています。例えば、abcdに対して`(.+)(.+)`をマッチさせる場合、最初の`(.+)`はabcにマッチし、2番目の`(.+)`はdにマッチする。Perlは、非貪欲バージョンとして`??, *?, +?`を導入しました。それらは、全体的なマッチを維持しながら、可能な限り小さい文字列とマッチします。例えば、abcdに対して`(.+?)(.+?)`をマッチさせる場合、最初の`(.+?)`はaのみにマッチし、2番目の`(.+?)`はbcdにマッチする。。定義上、演算子が貪欲であるかどうかは、正規表現が全体として特定の文字列にマッチするかどうかには影響しません。それはサブマッチ境界の選択にのみ影響します。バックトラックアルゴリズムでは、貪欲でない演算子を単純に実装することができます。つまり、長いものの前に短いマッチを試します。例えば、標準的なバックトラックの実装では、`e?`はまず`e`を試し、その次に`e`でない場合を試します。`e??`はその逆順で試します。Thompsonのアルゴリズムによるサブマッチ追跡の実装は、非貪欲な演算子に対応させることで実現できます。

アサーション(assertions)。伝統的な正規表現のメタキャラクタ`^`と`$`は、その周りのテキストについての アサーションとみなすことができます。 `^` は前の文字が改行（または文字列の先頭）であることを表し、`$` は次の文字が改行（または文字列の末尾）であることを表します。Perlはさらに多くのアサーションがあります。例えば、前の文字が英数字であるが、次の文字が英数字でないこと、またはその逆を表す単語境界`\b`のようなアサーションです。Perlはまた、ルックアヘッドアサーションと呼ばれる任意の条件にもその考えを一般化しました。例えば、 (?=re) は現在の入力位置の後にあるテキストが re にマッチすることを表しますが、入力位置を実際に進めることはありません。(?!re)も同様ですが、テキストがreにマッチしないことをアサートします。 ルックビハインドアサーション `(?<=re)` と `(?<!re)` は似ていますが、現在の入力位置より前のテキストについて アサーションを行います。`^,$,\b`のような単純なアサーションは、前方アサーションに対してマッチを1バイト遅らせるだけで、 NFAに対応させるのは簡単です。一般化されたアサーションは対応が難しいですが、原理的にはNFAでエンコードできます。

後方参照(backreferences)。前述したように、後方参照を使った正規表現を効率的に実装する方法は誰にもわからず、それが不可能であることさえも証明されていません。(具体的には、[この問題はNP完全です](https://perl.plover.com/NPC/NPC-3SAT.html)。つまり、もし誰かが効率的な実装を見つけたとしたら、それはコンピュータ科学者にとって大ニュースであり、[100万ドル](https://www.claymath.org/Popular_Lectures/Minesweeper/)の賞金を獲得することになるでしょう)。元のawkやegrepがとった後方参照に対する最も単純で効果的な戦略は、後方参照を実装しないことでした。この戦略はもはや実用的ではありません。ユーザは少なくとも時々は後方参照を使うようになりましたし、後方参照は[正規表現の POSIX 標準](http://www.opengroup.org/onlinepubs/009695399/basedefs/xbd_chap09.html)の一部です。それでも、ほとんどの正規表現にはThompsonのNFAシミュレーションを使い、必要なときだけバックトラックを導入するのが合理的でしょう。特に賢い実装では、この2つを組み合わせて、後方参照に対応するためだけにバックトラックを使うこともできます。

メモ化によるバックトラック(backtracking with memoization)。可能な限りバックトラック中の指数関数的な爆発を避けるためにメモ化を使うというPerlのアプローチは良いものです。少なくとも理論的には、Perlの正規表現がよりNFA的な振る舞いをするようになり、バックトラック的な振る舞いは少なくなるはずです。しかし、メモ化はこの問題を完全に解決するわけではありません。メモ化自体は、テキストのサイズに正規表現のサイズを掛けただけのメモリフットプリントを必要とします。メモ化はまた、バックトラックで使用されるスタックスペースの問題にも対処していません。スタックスペースはテキストのサイズに線形であり、長い文字列をマッチさせると、一般的にバックトラック実装はスタックスペースを使い果たしてしまいます。
```shell
$ perl -e '("a" x 100000) =~ /^(ab?)*$/;'
Segmentation fault (core dumped)
$
```

文字セット(character sets)。モダンな正規表現実装では、Unicodeのような大規模な非ASCII文字セットを扱わなければなりません。[Plan 9正規表現ライブラリ](https://9fans.github.io/plan9port/unix/)は、各ステップで1つのUnicode文字を入力文字としてNFAを実行することで、Unicodeを組み込んでいます。このライブラリはNFAの実行と入力のデコードを分離しているため、UTF-8([リンク切れ](http://plan9.bell-labs.com/sys/doc/utf.html))とワイド文字の両方の入力に対して同じ正規表現マッチングコードが使用されます。

## 歴史とリファレンス
Michael Rabin と Dana Scott は、1959年に非決定性有限オートマトンと非決定性の概念を導入し[7]、各DFAの状態がNFAの状態の集合に対応する(潜在的にはるかに大きい)DFAによってNFAをシミュレートできることを示した。(彼らはこの論文で非決定性の概念を導入したことで、1976年にチューリング賞を受賞した)。

R. McNaughton と H. Yamada [4]とKen Thompson [9]は、どちらの論文もNFAという当時の概念に言及していないにもかかわらず、正規表現をNFAに変換する最初の構文を与えたと一般的に信じられています。McNaughtonとYamadaの構文はDFAを作成し、Thompsonの構文はIBM 7094マシンコードを作成しますが、行間を読むと、両者の根底に潜在的なNFA構文があることがわかります。正規表現とNFA構築の違いは、NFAが行わなければならない選択をどのように符号化するかという点だけです。トンプソンを模倣した上記のアプローチでは、明示的な選択ノード（上記のスプリットノード）とラベルのない矢印で選択をエンコードします。別のアプローチとして、McNaughtonとYamadaが最もよく使った方法は、ラベルのない矢印を避け、代わりにNFAの状態が同じラベルを持つ複数の矢印を持つようにすることです。McIlroy [3]は、Haskellでこのアプローチを特にエレガントに実装しています。

Thompsonによる正規表現の実装は、IBM 7094上のCTSS [10]オペレーティングシステム上で動作するQEDエディタ用でした。このエディタのコピーは、CTSSのアーカイブソース[5]にあります。L. Peter DeutschとButler Lampson [1]は最初のQEDを開発しましたが、正規表現を使ったのはThompsonの再実装が最初です。別のQED実装の著者であるDennis Ritchieは、QEDエディタの初期の歴史を記録しています[8] (Thompson、Ritchie、Lampsonは、後にQEDや有限オートマトンとは関係のない仕事でチューリング賞を受賞しています)

Thompsonの論文は、正規表現の長い実装の始まりとなりました。トンプソンは、Unix第1版(1971年)に登場したテキストエディタedや、その子孫で第4版(1973年)に登場したgrepを実装する際に、彼のアルゴリズムを使わないことにしました。その代わりに、これらの由緒あるUnixツールは再帰的バックトラックを使いました! バックトラックが正当化されたのは、正規表現の構文がかなり限定されていたからで、グループ化括弧や`|, ? +`演算子は省略されていました。Al Ahoのegrepは第7版(1979年)で初めて登場し、事前に計算されたDFAを使用して、完全な正規表現構文を提供した最初のUnixツールでした。第8版(1985年)では、egrepは上記の実装のようにDFAをon-the-flyで計算するようになりました。

Rob Pikeは、1980年代初期にテキストエディタsam [6]を書いていたとき、新しい正規表現実装を書き、Dave Presottoがそれを第8版に登場するライブラリに取り込みました。Pikeの実装は、効率的なNFAシミュレーションにサブマッチ追跡を組み込んでいましたが、第8版の他のソースと同様、広く配布されることはありませんでした。Pike自身、自分のテクニックが目新しいものだとは気づいていませんでした。Henry Spencerは、第8版のライブラリインターフェースをゼロから再実装し、バックトラッキングを用いて、その実装をパブリックドメインとして公開([リンク切れ](https://www.arglist.com/regex/))しました。この実装は非常に広く使われるようになり、最終的には前述の遅い正規表現の実装の基礎となりました。Perl、PCRE、Pythonなどです。(彼の弁によれば、Spencerはルーチンが遅くなることを知っていたし、より効率的なアルゴリズムが存在することも知りませんでした。彼は「egrepの内部をこのコードで置き換えるのは間違いだが、多くのユーザーはこの速度で全く十分だと感じている」とドキュメントで警告してさえいました)。Unicodeをサポートするように拡張されたPikeの正規表現実装は、[1992年末](https://groups.google.com/g/comp.os.research/c/fvfHNv_t_Dw/m/UYDRogQ1ePEJ)にsamとともに自由に利用できるようになりましたが、特に効率的な正規表現検索アルゴリズムは気づかれることはありませんでした。このコードは現在、samの一部([リンク切れ](http://plan9.bell-labs.com/sources/plan9/sys/src/cmd/sam/))として、Plan 9の正規表現ライブラリ([リンク切れ](http://plan9.bell-labs.com/sources/plan9/sys/src/libregexp/))として、あるいは[Unix用に個別にパッケージされたもの](https://9fans.github.io/plan9port/unix/)など、さまざまな形で利用されています。Ville Laurikariは1999年にPikeのアルゴリズムを独自に発見し、理論的基礎も開発しました[2]。

最後に、おそらく今日のプログラマーの間で最も人気のある参考書であるJeffrey Friedl氏の著書「Mastering Regular Expressions」への言及なしに、どの正規表現の議論は完全でなかったでしょう。Friedl氏の本は、プログラマに今日の正規表現実装をどのように使うのがベストかを教えますが、どのように実装するのがベストかを教えていません。この本が実装の問題に割くわずかな文章は、再帰的バックトラックがNFAをシミュレートする唯一の方法であるという広まった信仰を蔓延させるものです。Friedl氏は、基礎となる理論を理解しておらず、また尊重していないことが明らかです。

## まとめ
正規表現のマッチングは、何十年も前から知られている有限オートマトンベースのテクニックを使うことで、シンプルかつ高速に行うことができます。対照的に、Perl、PCRE、Python、Ruby、Java、その他多くの言語では、再帰的バックトラックに基づく正規表現実装があり、単純ではあるが、耐えられないほど遅いことがあります。後方参照を除けば、バックトラック実装が遅く提供する機能を、オートマトンベースの実装は劇的に速く一貫した速度で提供することができます。

このシリーズの次の記事「[Regular Expression Matching: the Virtual Machine Approach](https://swtch.com/~rsc/regexp/regexp2.html)」では、NFAベースのサブマッチ抽出について説明します。3つ目の記事、「[Regular Expression Matching in the Wild](https://swtch.com/~rsc/regexp/regexp3.html)」では、実際の実装を検証します。4つ目の記事「[Regular Expression Matching with a Trigram Index](https://swtch.com/~rsc/regexp/regexp4.html)」は、Google Code Searchがどのように実装されたかを説明します。

## 謝辞
Lee Feigenbaum、James Grimmelmann、Alex Healy、William Josephson、Arnold Robbinsはこの記事のドラフトを読み、多くの有益な示唆を与えてくれました。Rob Pikeは、彼の正規表現実装にまつわる歴史のいくつかを明示してくれました。すべてに感謝します。
